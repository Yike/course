{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "css_file = '../../../msc/custom.css' \n",
    "HTML(open(css_file, 'r').read()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Generalized Roy Model\n",
    "\n",
    "**Roadmap**\n",
    "\n",
    "* Data Generating Process\n",
    "* Objects of Interest\n",
    "* Processing Specification\n",
    "* Setting up Simulation\n",
    "* Conducting Estimation\n",
    "\n",
    "Over the next couple of lectures, we will then constantly refine the basic code and explore elements of software engineering such as Object-Oriented Programming, Unit Testing, Debugging, and Profiling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generating Process\n",
    "\n",
    "The generalized Roy model is characterized by the following set of equations. \n",
    "\n",
    "**Potential Outcomes**\n",
    "\n",
    "\\begin{align}\n",
    "Y_1 &= X\\beta_1 + U_1 \\\\\n",
    "Y_0 &= X\\beta_0 + U_0 \n",
    "\\end{align}\n",
    "\n",
    "**Cost**\n",
    "\n",
    "\\begin{align}\n",
    "C = Z\\gamma + V\n",
    "\\end{align}\n",
    "\n",
    "**Choice**\n",
    "\n",
    "\\begin{align}\n",
    "S &= Y_1 - Y_0 - C\\\\\n",
    "D &= I[S > 0]\n",
    "\\end{align}\n",
    "\n",
    "**Observed Outcome**\n",
    "\n",
    "\\begin{align}\n",
    "Y = D Y_1 + (1 - D)Y_0\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "$(Y_1, Y_0)$ are objective outcomes associated with each potential treatment state $D$ and realized after the treatment decision. $Y_1$ refers to the outcome in the treated state and $Y_0$ in the untreated state. $C$ denotes the subjective cost of treatment participation. Any subjective benefits,e.g. job amenities, are included (as a negative contribution) in the subjective cost of treatment. Agents take up treatment $D$ if they expect the objective benefit to outweigh the subjective cost. In that case, their subjective evaluation, i.e. the expected surplus from participation $S$, is positive. If agents take up treatment, then the observed outcome $Y$ corresponds to the outcome in the presence of treatment $Y_1$. Otherwise, $Y_0$ is observed. The unobserved potential outcome is referred to as the counterfactual outcome. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objects of Interest\n",
    "\n",
    "**Individual-specific Treatment Effect**\n",
    "\n",
    "\\begin{align}\n",
    "B = Y_1 - Y_0 = X(\\beta_1 - \\beta_0) + (U_1 - U_0)\n",
    "\\end{align}\n",
    "\n",
    "* Heterogeneity\n",
    " * Observed\n",
    " * Unobserved\n",
    " \n",
    "**Average Treatment Effect**\n",
    "\n",
    "\\begin{align}\n",
    "ATE & = E\\left[Y_1 - Y_0 \\right]\\\\\n",
    "TT  & = E\\left[Y_1 - Y_0 \\mid D = 1\\right]\\\\\n",
    "TUT & = E\\left[Y_1 - Y_0 \\mid D = 0\\right]\n",
    "\\end{align}\n",
    "\n",
    "**Distribution of Potential Outcomes**\n",
    "\n",
    "\\begin{align}\n",
    "F_{Y_1,Y_0}\n",
    "\\end{align}\n",
    "\n",
    "* Distribution of Benefits\n",
    " * Heterogeneity\n",
    " * Population Shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Information\n",
    "\n",
    "To be collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing of Model Specification\n",
    "\n",
    "We manage the model specification in an external text file, which is called *init.ini*. This file will turn out to be useful to provide the parameters for a simulation of a synthetic sample or the initialization of starting values for an estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images/init.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will develop a function that processes the initialization file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _check_integrity(dict_):\n",
    "    ''' Check integrity of initFile dict.\n",
    "    '''\n",
    "    # Antibugging \n",
    "    assert (isinstance(dict_, dict))\n",
    "    \n",
    "    # Check number of agents \n",
    "    assert (dict_['BASICS']['agents'] > 0)\n",
    "    assert (isinstance(dict_['BASICS']['agents'], int))\n",
    "    \n",
    "    # Finishing \n",
    "    return True\n",
    "\n",
    "def _add_auxiliary(dict_):\n",
    "    ''' Add some auxiliary objects.\n",
    "    '''\n",
    "    # Antibugging \n",
    "    assert (isinstance(dict_, dict))\n",
    "    \n",
    "    # Initialize container\n",
    "    dict_['AUX'] = {}\n",
    "    \n",
    "    # Full set of coefficients.\n",
    "    dict_['TREATED']['all']  = [dict_['TREATED']['int']]\n",
    "    dict_['TREATED']['all'] += dict_['TREATED']['coeff']\n",
    "    dict_['TREATED']['all']  = np.array(dict_['TREATED']['all'])\n",
    "\n",
    "    dict_['UNTREATED']['all']  = [dict_['UNTREATED']['int']]\n",
    "    dict_['UNTREATED']['all'] += dict_['UNTREATED']['coeff']\n",
    "    dict_['UNTREATED']['all']  = np.array(dict_['UNTREATED']['all'])\n",
    "    \n",
    "    dict_['COST']['all'] = np.array(dict_['COST']['coeff'])\n",
    "    \n",
    "    # Number of covariates\n",
    "    num_covars_out = len(dict_['TREATED']['coeff']) + 1\n",
    "    num_covars_cost = len(dict_['COST']['coeff']) \n",
    "\n",
    "    dict_['AUX']['num_covars_out']  = num_covars_out\n",
    "    dict_['AUX']['num_covars_cost'] = num_covars_cost\n",
    "    \n",
    "    # Number of parameters\n",
    "    dict_['AUX']['num_paras'] = 2*num_covars_out + num_covars_cost + 2 + 2\n",
    "    \n",
    "    # Starting values\n",
    "    dict_['AUX']['start_values']  = []\n",
    "    dict_['AUX']['start_values'] += [dict_['TREATED']['int']]\n",
    "    dict_['AUX']['start_values'] += dict_['TREATED']['coeff']\n",
    "    dict_['AUX']['start_values'] += [dict_['UNTREATED']['int']]\n",
    "    dict_['AUX']['start_values'] += dict_['UNTREATED']['coeff']\n",
    "    dict_['AUX']['start_values'] += dict_['COST']['coeff']\n",
    "    dict_['AUX']['start_values'] += [dict_['TREATED']['var']]\n",
    "    dict_['AUX']['start_values'] += [dict_['UNTREATED']['var']]\n",
    "    dict_['AUX']['start_values'] += [dict_['RHO']['treated']]\n",
    "    dict_['AUX']['start_values'] += [dict_['RHO']['untreated']]\n",
    "    \n",
    "    # Finishing\n",
    "    return dict_\n",
    "\n",
    "def _process_cases(list_):\n",
    "    \"\"\" Process cases and determine whether keyword or empty \n",
    "        line.\n",
    "    \"\"\"\n",
    "    # Antibugging\n",
    "    assert (isinstance(list_, list))\n",
    "\n",
    "    # Initialize containers \n",
    "    is_empty, is_keyword = None, None\n",
    "    \n",
    "    # Get information \n",
    "    is_empty = (len(list_) == 0)\n",
    "    \n",
    "    if not is_empty:\n",
    "        is_keyword = list_[0].isupper()\n",
    "    else:\n",
    "        is_keyword = False\n",
    "        \n",
    "    # Antibugging \n",
    "    assert (is_keyword in [True, False])\n",
    "    assert (is_empty in [True, False])\n",
    "    \n",
    "    # Finishing \n",
    "    return is_empty, is_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shlex\n",
    "\n",
    "def read_init():\n",
    "    ''' This function reads the init.ini file.\n",
    "    '''\n",
    "    # Initialization\n",
    "    dict_ = {}\n",
    "    \n",
    "    # Core part\n",
    "    raise Assertion 'code missing'\n",
    "\n",
    "    # Add auxiliary objects\n",
    "    dict_ = _add_auxiliary(dict_)\n",
    "                \n",
    "    # Check quality.\n",
    "    _check_integrity(dict_)\n",
    "    \n",
    "    # Finishing.\n",
    "    return dict_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check if it is all working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_dict = read_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Simulation\n",
    "\n",
    "**Distributinal Assumptions**\n",
    "\n",
    "*Observables*\n",
    "\\begin{align}\n",
    "X & \\sim \\mathbb{N}(0, 1) \\\\\n",
    "Z & \\sim \\mathbb{N}(0, 1) \\\\\n",
    "\\end{align}\n",
    "\n",
    "*Unobservables*  \n",
    "\\begin{align}\n",
    "U_1 & \\sim \\mathbb{N}(0, \\sigma_{U_1}) \\\\\n",
    "U_0 & \\sim \\mathbb{N}(0, \\sigma_{U_0}) \\\\\n",
    "V   & \\sim \\mathbb{N}(0, \\sigma_{V})\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_dict = read_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_integrity(Y1, Y0, Y, D):\n",
    "    ''' Check quality of simulated sample. \n",
    "    '''\n",
    "    assert (np.all(np.isfinite(Y1)))\n",
    "    assert (np.all(np.isfinite(Y0)))\n",
    "\n",
    "    assert (np.all(np.isfinite(Y)))\n",
    "    assert (np.all(np.isfinite(D)))\n",
    "\n",
    "    assert (Y1.dtype == 'float')\n",
    "    assert (Y0.dtype == 'float')\n",
    "\n",
    "    assert (Y.dtype == 'float')\n",
    "    assert (D.dtype == 'float')\n",
    "\n",
    "    assert ((D.all() in [1.0, 0.0]))\n",
    "    \n",
    "def write_out(Y, D, X, Z, file_name):\n",
    "    ''' Write out simulated data to file.\n",
    "    '''\n",
    "    \n",
    "    np.savetxt(file_name, np.column_stack((Y, D, X, Z)), fmt= '%8.3f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "import os\n",
    "\n",
    "def simulate_model():\n",
    "    ''' Simulate a model based on the initialization file.\n",
    "    '''\n",
    "    \n",
    "    # Antibugging\n",
    "    assert (os.path.exists('init.ini'))\n",
    "    \n",
    "    # Read specification\n",
    "    init_dict = read_init()\n",
    "    \n",
    "    # Distribute information\n",
    "    num_agents = init_dict['BASICS']['agents']\n",
    "    file_name  = init_dict['BASICS']['file']\n",
    "\n",
    "    Y1_coeffs  = init_dict['TREATED']['all']\n",
    "    Y0_coeffs  = init_dict['UNTREATED']['all']\n",
    "    \n",
    "    C_coeffs   = np.array(init_dict['COST']['coeff'])\n",
    "\n",
    "    U1_var     = init_dict['TREATED']['var'] \n",
    "    U0_var     = init_dict['UNTREATED']['var']  \n",
    "\n",
    "    V_var      = init_dict['COST']['var']\n",
    "\n",
    "    U1V_rho    = init_dict['RHO']['treated']  \n",
    "    U0V_rho    = init_dict['RHO']['untreated']\n",
    "    \n",
    "    # Auxiliary objects\n",
    "    U1V_cov    = U1V_rho*np.sqrt(U1_var)*np.sqrt(V_var)\n",
    "    U0V_cov    = U0V_rho*np.sqrt(U0_var)*np.sqrt(V_var)\n",
    "\n",
    "    num_covars_out  = Y1_coeffs.shape[0]\n",
    "    num_covars_cost = C_coeffs.shape[0]\n",
    "\n",
    "    # Simulate observables\n",
    "    raise Assertion 'missing code'\n",
    "\n",
    "    # Construct index of observable characteristics\n",
    "    Y1_level = np.dot(Y1_coeffs, X.T)\n",
    "    Y0_level = np.dot(Y0_coeffs, X.T)\n",
    "    C_level  = np.dot(C_coeffs, Z.T)\n",
    "    \n",
    "    # Simulate unobservables\n",
    "    means = np.tile(0.0, 3)\n",
    "    vars_ = [U1_var, U0_var, V_var]\n",
    "    covs  = np.diag(vars_)\n",
    "\n",
    "    covs[0,2] = U1V_cov \n",
    "    covs[2,0] = covs[0,2]\n",
    "\n",
    "    covs[1,2] = U0V_cov\n",
    "    covs[2,1] = covs[1,2]\n",
    "\n",
    "    U = np.random.multivariate_normal(means, covs, num_agents)\n",
    "    \n",
    "    # Simulate endogenous variables\n",
    "    Y1 = np.tile(np.nan, (num_agents))\n",
    "    Y0 = np.tile(np.nan, (num_agents))\n",
    "    Y  = np.tile(np.nan, (num_agents))\n",
    "\n",
    "    D  = np.tile(np.nan, (num_agents))\n",
    "\n",
    "    for i in range(num_agents):\n",
    "        raise AssertionError 'code missing'\n",
    "\n",
    "    # Save to disk\n",
    "    write_out(Y, D, X, Z, file_name)\n",
    "    \n",
    "    # Return selected features of data\n",
    "    return Y1, Y0, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check if it is all working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y1, Y0, D = simulate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our parametrization, let us revisit our objects of interest. We start with the individual-specific benefits. Please note the use of the [StatsModels](http://statsmodels.sourceforge.net/devel/index.html) library,\n",
    "that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration. Think of it as a replacement for using [R](http://www.r-project.org/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import of libraries\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "# Auxiliary variables\n",
    "B = Y1 - Y0\n",
    "\n",
    "# Create histogram and density estimate of benefits.\n",
    "kde = sm.nonparametric.KDEUnivariate(B)\n",
    "kde.fit()\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(B, bins=50, normed=True, color='blue')\n",
    "ax.plot(kde.support, kde.density, lw=2, color='black')\n",
    "\n",
    "# Calcuate the average treatment effects\n",
    "ate, tt, tut = np.mean(B), np.mean(B[D==1]), np.mean(B[D==0])\n",
    "\n",
    "# Pretty formatting of strings and output\n",
    "fmt = '     {0:<5}{1:10.2f}\\n'\n",
    "\n",
    "print '\\nAverage Treatment Effects\\n'\n",
    "print fmt.format('ATE ', ate)\n",
    "print fmt.format('TT', tt)\n",
    "print fmt.format('TUT ', tut)\n",
    "\n",
    "# Let us add them to our plot.\n",
    "plt.axvline(x=ate, ymin=0, ymax=5, linewidth=2, color='g')\n",
    "plt.axvline(x=tt, ymin=0, ymax=5, linewidth=2, color='b')\n",
    "plt.axvline(x=tut, ymin=0, ymax=5, linewidth=2, color='y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "\n",
    "Now, we will perform Maximum Likelihood Estimation using alternative optimization algorithms. Here is the likelihood function:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta; X, Z) =\\sum^N_{i=1} D\\mathcal{L_1} + (1 - D)\\mathcal{L_1},\n",
    "\\end{align}\n",
    "where\n",
    "\\begin{align}\n",
    "\\mathcal{L_1} = & \\log\\left(\\frac{1}{\\sigma_{U_1}}\\phi\\left(\\frac{Y_i - X_i\\beta}{\\sigma_{U_1}}\\right)\\Phi\\left(\\frac{Z_i\\gamma - \\rho_{U_1,V}(Y_i - X_i\\beta)/\\sigma_{U_1}}{\\sqrt{1 - \\rho_{U_1,V}}}\\right)\\right) \\\\\n",
    "\\mathcal{L_0} =  &\\log\\left(\\frac{1}{\\sigma_{U_0}}\\phi\\left(\\frac{Y_i - X_i\\beta}{\\sigma_{U_0}}\\right)\\Phi\\left(\\frac{Z_i\\gamma - \\rho_{U_0,V}(Y_i - X_i\\beta)/\\sigma_{U_0}}{\\sqrt{1 - \\rho_{U_0,V}}}\\right)\\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats    import norm\n",
    "\n",
    "def _distribute_parameters(x, num_covars_out):\n",
    "    ''' Distribute the parameters.\n",
    "    '''       \n",
    "    # Antibugging\n",
    "    assert (isinstance(x, np.ndarray))\n",
    "    assert (isinstance(num_covars_out, int))\n",
    "    assert (num_covars_out > 0)\n",
    "    \n",
    "    # Initialize containers\n",
    "    rslt = {}\n",
    "\n",
    "    # Distribute parameters\n",
    "    rslt['Y1_coeffs'] = x[:num_covars_out]\n",
    "    rslt['Y0_coeffs'] = x[num_covars_out:(2*num_covars_out)]\n",
    "    \n",
    "    rslt['C_coeffs'] = x[(2*num_covars_out):(-4)]\n",
    "    \n",
    "    rslt['U1_var']  = np.exp(x[(-4)])\n",
    "    rslt['U0_var']  = np.exp(x[(-3)])\n",
    "\n",
    "    rslt['U1V_rho'] = -1.0 + 2.0/(1.0 + np.exp(-x[-2]))    \n",
    "    rslt['U0V_rho'] = -1.0 + 2.0/(1.0 + np.exp(-x[-1])) \n",
    "\n",
    "    # Finishing.\n",
    "    return rslt\n",
    "\n",
    "def _negative_log_likelihood(args, Y, D, X, Z):\n",
    "    ''' Negative Log-likelihood function of the Generalized Roy Model.\n",
    "    '''   \n",
    "    # Distribute parametrization\n",
    "    Y1_coeffs   = np.array(args['Y1_coeffs'])\n",
    "    Y0_coeffs   = np.array(args['Y0_coeffs'])\n",
    "    \n",
    "    C_coeffs    = np.array(args['C_coeffs'])\n",
    "    \n",
    "    U1_var    = args['U1_var'] \n",
    "    U0_var    = args['U0_var'] \n",
    "    \n",
    "    U1V_rho   = args['U1V_rho']\n",
    "    U0V_rho   = args['U0V_rho']\n",
    "\n",
    "    # Auxiliary objects.\n",
    "    num_agents   = Y.shape[0]\n",
    "    choiceCoeffs = np.concatenate((Y1_coeffs - Y0_coeffs, - C_coeffs))\n",
    "    \n",
    "    # Likelihood construction.\n",
    "    likl = 0.00\n",
    "        \n",
    "    for i in range(num_agents):\n",
    "            \n",
    "       raise AssertionError, 'code missing'\n",
    "    \n",
    "    # Quality checks.\n",
    "    assert (isinstance(likl, float))\n",
    "    assert (np.isfinite(likl))\n",
    "    \n",
    "    # Finishing.\n",
    "    return likl\n",
    "\n",
    "def load_data():\n",
    "    ''' Load dataset.\n",
    "    '''\n",
    "    init_dict = read_init()\n",
    "    \n",
    "    # Auxiliary objects\n",
    "    num_covars_out  = init_dict['AUX']['num_covars_out']\n",
    "    num_covars_cost = init_dict['AUX']['num_covars_cost']\n",
    "    \n",
    "    # Read dataset\n",
    "    data = np.genfromtxt(init_dict['BASICS']['file'])\n",
    "\n",
    "    # Distribute data\n",
    "    Y, D = data[:,0], data[:,1]\n",
    "\n",
    "    X, Z = data[:,2:(num_covars_out + 2)], data[:,-num_covars_cost:]\n",
    "\n",
    "    # Finishing\n",
    "    return Y, D, X, Z\n",
    "\n",
    "def _max_interface(x, Y, D, X, Z):\n",
    "    ''' Interface to the SciPy maximization routines.\n",
    "    '''\n",
    "    # Auxiliary objects.\n",
    "    num_covars_out = X.shape[1]\n",
    "    \n",
    "    # Collect maximization arguments.\n",
    "    rslt = _distribute_parameters(x, num_covars_out)\n",
    "    \n",
    "    # Calculate likelihood.\n",
    "    likl = _negative_log_likelihood(rslt, Y, D, X, Z)\n",
    "        \n",
    "    # Finishing.\n",
    "    return likl\n",
    "\n",
    "def get_start(which):\n",
    "    ''' Get different kind of starting values.\n",
    "    '''\n",
    "    # Antibugging.\n",
    "    assert (which in ['zeros', 'random', 'init'])\n",
    "    \n",
    "    # Select relevant values.\n",
    "    if which == 'zeros':\n",
    "        x0 = np.zeros(num_paras)\n",
    "    elif which == 'random':\n",
    "        x0 = numpy.random.uniform(size=num_paras)\n",
    "    elif which =='init':\n",
    "        x0 = init_dict['AUX']['start_values']\n",
    "    else:\n",
    "        raise AssertionError\n",
    "\n",
    "    # Quality assurance.\n",
    "    assert (np.all(np.isfinite(x0)))\n",
    "\n",
    "    # Finishing.\n",
    "    return x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us evaluate the criterion function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model information\n",
    "init_dict  = read_init() \n",
    "\n",
    "Y, D, X, Z = load_data()\n",
    "\n",
    "'Set up the parametrization. '\n",
    "args = {}\n",
    "\n",
    "args['Y1_coeffs'] = np.array(init_dict['TREATED']['all'])\n",
    "args['Y0_coeffs'] = np.array(init_dict['UNTREATED']['all'])\n",
    "\n",
    "args['C_coeffs'] = np.array(init_dict['COST']['all'])\n",
    "\n",
    "args['U1_var']  = init_dict['TREATED']['var']\n",
    "args['U0_var']  = init_dict['UNTREATED']['var']\n",
    "\n",
    "args['U1V_rho'] = init_dict['RHO']['treated']\n",
    "args['U0V_rho'] = init_dict['RHO']['untreated']\n",
    "\n",
    "likl = _negative_log_likelihood(args, Y, D, X, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now run the estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Load model information\n",
    "init_dict = read_init()\n",
    "\n",
    "Y, D, X, Z = load_data()\n",
    "\n",
    "# Create auxiliary objects\n",
    "num_paras = init_dict['AUX']['num_paras']\n",
    "\n",
    "# Initialize different starting values\n",
    "x0 = get_start('init')\n",
    "    \n",
    "# Call alternative optimizers\n",
    "opts = {}\n",
    "\n",
    "opts['maxiter'] = 1\n",
    "\n",
    "for optimizer in ['BFGS', 'Nelder-Mead']:\n",
    "    \n",
    "    rslt = minimize(_max_interface, x0, args=(Y, D, X, Z), \n",
    "                    method=optimizer, options=opts)\n",
    "    \n",
    "    # Tranformation to internal parameters\n",
    "    num_covars_out = init_dict['AUX']['num_covars_out']\n",
    "\n",
    "    parameters = _distribute_parameters(rslt['x'], num_covars_out) \n",
    "\n",
    "    print '\\n Optimizer ', optimizer\n",
    "    print parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    os.remove('dataset.txt')\n",
    "    \n",
    "except OSError:\n",
    "    \n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
