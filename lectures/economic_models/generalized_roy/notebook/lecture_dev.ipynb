{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "css_file = '../../../../msc/custom.css' \n",
    "HTML(open(css_file, 'r').read()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Generalized Roy Model\n",
    "\n",
    "**Roadmap**\n",
    "\n",
    "* Data Generating Process\n",
    "* Objects of Interest\n",
    "* Processing Specification\n",
    "* Setting up Simulation\n",
    "* Conducting Estimation\n",
    "* Inspection of Results\n",
    "\n",
    "Over the next couple of lectures, we will then constantly refine the basic code and explore elements of software engineering such as Object-Oriented Programming, Unit Testing, Debugging, and Profiling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generating Process\n",
    "\n",
    "The generalized Roy model is characterized by the following set of equations. \n",
    "\n",
    "**Potential Outcomes**\n",
    "\n",
    "\\begin{align}\n",
    "Y_1 &= X\\beta_1 + U_1 \\\\\n",
    "Y_0 &= X\\beta_0 + U_0 \n",
    "\\end{align}\n",
    "\n",
    "**Cost**\n",
    "\n",
    "\\begin{align}\n",
    "C = Z\\gamma + V\n",
    "\\end{align}\n",
    "\n",
    "**Choice**\n",
    "\n",
    "\\begin{align}\n",
    "S &= Y_1 - Y_0 - C\\\\\n",
    "D &= I[S > 0]\n",
    "\\end{align}\n",
    "\n",
    "**Observed Outcome**\n",
    "\n",
    "\\begin{align}\n",
    "Y = D Y_1 + (1 - D)Y_0\n",
    "\\end{align}\n",
    "\n",
    "$(Y_1, Y_0)$ are objective outcomes associated with each potential treatment state $D$ and realized after the treatment decision. $Y_1$ refers to the outcome in the treated state and $Y_0$ in the untreated state. $C$ denotes the subjective cost of treatment participation. Any subjective benefits,e.g. job amenities, are included (as a negative contribution) in the subjective cost of treatment. Agents take up treatment $D$ if they expect the objective benefit to outweigh the subjective cost. In that case, their subjective evaluation, i.e. the expected surplus from participation $S$, is positive. If agents take up treatment, then the observed outcome $Y$ corresponds to the outcome in the presence of treatment $Y_1$. Otherwise, $Y_0$ is observed. The unobserved potential outcome is referred to as the counterfactual outcome. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objects of Interest\n",
    "\n",
    "**Individual-specific Treatment Effect**\n",
    "\n",
    "\\begin{align}\n",
    "B = Y_1 - Y_0 = X(\\beta_1 - \\beta_0) + (U_1 - U_0)\n",
    "\\end{align}\n",
    "\n",
    "* Heterogeneity\n",
    " * Observed\n",
    " * Unobserved\n",
    " \n",
    "**Average Treatment Effect**\n",
    "\n",
    "\\begin{align}\n",
    "ATE & = E\\left[Y_1 - Y_0 \\right]\\\\\n",
    "TT  & = E\\left[Y_1 - Y_0 \\mid D = 1\\right]\\\\\n",
    "TUT & = E\\left[Y_1 - Y_0 \\mid D = 0\\right]\n",
    "\\end{align}\n",
    "\n",
    "<img src=\"images/treatment_effects.png\">\n",
    "\n",
    "** Choice **\n",
    "\n",
    "\\begin{align}\n",
    "D & = \\mathbb{1}\\{S>0\\}\\\\\n",
    "S & = Y_1 - Y_0 - C\\\\\n",
    "C & = \\mu_C(Z) + U_C\n",
    "\\end{align}\n",
    "\n",
    "* Propensity score:\n",
    "\n",
    "\\begin{align}\n",
    "P(X,Z) = Pr(D = 1 | X,Z) = F_V(\\mu_S(X,Z))\n",
    "\\end{align}\n",
    "\n",
    "* Choice equation can be rewritten as:\n",
    "\n",
    "\\begin{align}\n",
    "D & = \\mathbb{1}\\{P(X,Z) > U_S\\}\\\\\n",
    "\\end{align}\n",
    "\n",
    "**Marginal Treatment Effect**\n",
    "\n",
    "The *MTE* is the treatment effect parameter that conditions on the unobserved desire to select into treatment. Let $V = U_C - (U_1 - U_0)$ and $U_S = F_V (V)$. Then, *Marginal Benefit*, *Marginal Cost* and *Marginal Surplus* are defined as:\n",
    "\n",
    "\\begin{align}\n",
    "B^{MTE}(x,u_S) & = E[Y_1 - Y_0|X = x,U_S = u_S]\\\\\n",
    "C^{MTE}(z,u_S) & = E[C|Z = z,U_S = u_S]\\\\\n",
    "S^{MTE}(x,z,u_S) & = E[S|X = x,Z = z, U_S = u_S]\n",
    "\\end{align}\n",
    "\n",
    "<img src=\"images/marginalRelationships.png\">\n",
    "\n",
    "**Distribution of Potential Outcomes**\n",
    "\n",
    "\\begin{align}\n",
    "F_{Y_1,Y_0}\n",
    "\\end{align}\n",
    "\n",
    "* Distribution of Benefits\n",
    " * Heterogeneity\n",
    " * Population Shares\n",
    "\n",
    "<img src=\"images/joint_dist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For additional information, please see the References section at the end of the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, let us import some basic libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unix Pattern Extensions\n",
    "import glob\n",
    "\n",
    "# Operating System Interfaces\n",
    "import os\n",
    "\n",
    "# Lexical Analysis\n",
    "import shlex\n",
    "\n",
    "# Copy operations\n",
    "import copy\n",
    "\n",
    "# Statistical Modeling and Econometrics  \n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Plotting \n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline --no-import-all\n",
    "\n",
    "# Scientific Computing \n",
    "import numpy as np\n",
    "from scipy.stats    import norm\n",
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing of Model Specification\n",
    "\n",
    "We manage the model specification in an external text file, which is called *init.ini*. This file will turn out to be useful to provide the parameters for a simulation of a synthetic sample or the initialization of starting values for an estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images/init.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will develop a set of function that processes the initialization file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _check_integrity_process(dict_):\n",
    "    \"\"\" Check integrity of initFile dict.\n",
    "    \"\"\"\n",
    "    # Antibugging\n",
    "    assert (isinstance(dict_, dict))\n",
    "\n",
    "    # Check number of agents\n",
    "    assert (dict_['BASICS']['agents'] > 0)\n",
    "    assert (isinstance(dict_['BASICS']['agents'], int))\n",
    "\n",
    "    # Check optimizer\n",
    "    assert (dict_['ESTIMATION']['optimizer'] in ['bfgs', 'nm'])\n",
    "\n",
    "    # Check starting values\n",
    "    assert (dict_['ESTIMATION']['start'] in ['random', 'init'])\n",
    "\n",
    "    # Maximum iterations\n",
    "    assert (dict_['ESTIMATION']['maxiter'] >= 0)\n",
    "\n",
    "    # Finishing\n",
    "    return True\n",
    "\n",
    "\n",
    "def _add_auxiliary(dict_):\n",
    "    \"\"\" Add some auxiliary objects.\n",
    "    \"\"\"\n",
    "    # Antibugging\n",
    "    assert (isinstance(dict_, dict))\n",
    "\n",
    "    # Initialize container\n",
    "    dict_['AUX'] = {}\n",
    "\n",
    "    # Full set of coefficients.\n",
    "    dict_['TREATED']['all'] = [dict_['TREATED']['int']]\n",
    "    dict_['TREATED']['all'] += dict_['TREATED']['coeff']\n",
    "    dict_['TREATED']['all'] = np.array(dict_['TREATED']['all'])\n",
    "\n",
    "    dict_['UNTREATED']['all'] = [dict_['UNTREATED']['int']]\n",
    "    dict_['UNTREATED']['all'] += dict_['UNTREATED']['coeff']\n",
    "    dict_['UNTREATED']['all'] = np.array(dict_['UNTREATED']['all'])\n",
    "\n",
    "    dict_['COST']['all'] = np.array(dict_['COST']['coeff'])\n",
    "\n",
    "    # Number of covariates\n",
    "    num_covars_out = len(dict_['TREATED']['coeff']) + 1\n",
    "    num_covars_cost = len(dict_['COST']['coeff'])\n",
    "\n",
    "    dict_['AUX']['num_covars_out'] = num_covars_out\n",
    "    dict_['AUX']['num_covars_cost'] = num_covars_cost\n",
    "\n",
    "    # Number of parameters\n",
    "    dict_['AUX']['num_paras'] = 2 * num_covars_out + num_covars_cost + 2 + 2\n",
    "\n",
    "    # Starting values\n",
    "    dict_['AUX']['init_values'] = []\n",
    "    dict_['AUX']['init_values'] += [dict_['TREATED']['int']]\n",
    "    dict_['AUX']['init_values'] += dict_['TREATED']['coeff']\n",
    "    dict_['AUX']['init_values'] += [dict_['UNTREATED']['int']]\n",
    "    dict_['AUX']['init_values'] += dict_['UNTREATED']['coeff']\n",
    "    dict_['AUX']['init_values'] += dict_['COST']['coeff']\n",
    "    dict_['AUX']['init_values'] += [dict_['TREATED']['var']]\n",
    "    dict_['AUX']['init_values'] += [dict_['UNTREATED']['var']]\n",
    "    dict_['AUX']['init_values'] += [dict_['RHO']['treated']]\n",
    "    dict_['AUX']['init_values'] += [dict_['RHO']['untreated']]\n",
    "\n",
    "    # Finishing\n",
    "    return dict_\n",
    "\n",
    "\n",
    "def _process_cases(list_):\n",
    "    \"\"\" Process cases and determine whether keyword or empty\n",
    "        line.\n",
    "    \"\"\"\n",
    "    # Antibugging\n",
    "    assert (isinstance(list_, list))\n",
    "\n",
    "    # Get information\n",
    "    is_empty = (len(list_) == 0)\n",
    "\n",
    "    if not is_empty:\n",
    "        is_keyword = list_[0].isupper()\n",
    "    else:\n",
    "        is_keyword = False\n",
    "\n",
    "    # Antibugging\n",
    "    assert (is_keyword in [True, False])\n",
    "    assert (is_empty in [True, False])\n",
    "\n",
    "    # Finishing\n",
    "    return is_empty, is_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(file_):\n",
    "    \"\"\" This function reads the init.ini file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization\n",
    "    dict_ = {}\n",
    "\n",
    "    for line in open(file_).readlines():\n",
    "\n",
    "        list_ = shlex.split(line)\n",
    "\n",
    "        # Determine special cases\n",
    "        is_empty, is_keyword = _process_cases(list_)\n",
    "\n",
    "        # Applicability\n",
    "        if is_empty:\n",
    "            continue\n",
    "\n",
    "        if is_keyword:\n",
    "            keyword = list_[0]\n",
    "            dict_[keyword] = {}\n",
    "            continue\n",
    "\n",
    "        # Distribute information\n",
    "        name, val = list_[0], list_[1]\n",
    "\n",
    "        # Prepare container.\n",
    "        if name not in dict_[keyword].keys():\n",
    "\n",
    "            if name in ['coeff']:\n",
    "                dict_[keyword][name] = []\n",
    "\n",
    "        # Type conversion\n",
    "        if name in ['agents', 'maxiter']:\n",
    "            val = int(val)\n",
    "        elif name in ['file', 'optimizer', 'start', 'version']:\n",
    "            val = str(val)\n",
    "        else:\n",
    "            val = float(val)\n",
    "\n",
    "        # Collect information\n",
    "        if name in ['coeff']:\n",
    "            dict_[keyword][name] += [val]\n",
    "        else:\n",
    "            dict_[keyword][name] = val\n",
    "\n",
    "    # Add auxiliary objects\n",
    "    dict_ = _add_auxiliary(dict_)\n",
    "\n",
    "    # Check quality.\n",
    "    _check_integrity_process(dict_)\n",
    "\n",
    "    # Finishing.\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check if it is all working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_dict = process('init.ini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Simulation\n",
    "\n",
    "**Distributinal Assumptions**\n",
    "\n",
    "*Observables*\n",
    "\n",
    "\\begin{align}\n",
    "X & \\sim \\mathbb{N}(0, 1) \\\\\n",
    "Z & \\sim \\mathbb{N}(0, 1) \\\\\n",
    "\\end{align}\n",
    "\n",
    "*Unobservables*  \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\begin{pmatrix}U_{1}\\\\\n",
    "U_{0}\\\\\n",
    "V\n",
    "\\end{pmatrix} & \\sim & \\mathbb{N}\\left[\\left(\\begin{array}{c}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right),\\left(\\begin{array}{ccc}\n",
    "\\sigma_{U_1}^2 & 0 & \\sigma_{U_1,V}\\\\\n",
    "0 & \\sigma_{U_0}^2 & \\sigma_{U_0,V}\\\\\n",
    "\\sigma_{U_1,V} & \\sigma_{U_0,V} & \\sigma_{V}^2\n",
    "\\end{array}\\right)\\right]\\\\\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_dict = process('init.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _check_integrity_simulate(Y1, Y0, Y, D):\n",
    "    \"\"\" Check quality of simulated sample.\n",
    "    \"\"\"\n",
    "    assert (np.all(np.isfinite(Y1)))\n",
    "    assert (np.all(np.isfinite(Y0)))\n",
    "\n",
    "    assert (np.all(np.isfinite(Y)))\n",
    "    assert (np.all(np.isfinite(D)))\n",
    "\n",
    "    assert (Y1.dtype == 'float')\n",
    "    assert (Y0.dtype == 'float')\n",
    "\n",
    "    assert (Y.dtype == 'float')\n",
    "    assert (D.dtype == 'float')\n",
    "\n",
    "    assert (D.all() in [1.0, 0.0])\n",
    "\n",
    "\n",
    "def _write_out(Y, D, X, Z, file_name, unobserved=False, Y1=None, Y0=None):\n",
    "    \"\"\" Write out simulated data to file.\n",
    "    \"\"\"\n",
    "\n",
    "    if not unobserved:\n",
    "\n",
    "        np.savetxt(file_name, np.column_stack((Y, D, X, Z)), fmt='%8.3f')\n",
    "\n",
    "    else:\n",
    "\n",
    "        assert (isinstance(Y1, np.ndarray))\n",
    "        assert (isinstance(Y0, np.ndarray))\n",
    "\n",
    "        np.savetxt(file_name, np.column_stack((Y, D, X, Z, Y1, Y0)),\n",
    "                   fmt='%8.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate(init_dict, unobserved=False):\n",
    "    \"\"\" Simulate a model based on the initialization file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Antibugging\n",
    "    assert (isinstance(init_dict, dict))\n",
    "    assert (unobserved in [True, False])\n",
    "\n",
    "    # Ensure recomputability\n",
    "    np.random.seed(123)\n",
    "\n",
    "    # Distribute information\n",
    "    num_agents = init_dict['BASICS']['agents']\n",
    "    file_name = init_dict['BASICS']['file']\n",
    "\n",
    "    Y1_coeffs = init_dict['TREATED']['all']\n",
    "    Y0_coeffs = init_dict['UNTREATED']['all']\n",
    "\n",
    "    C_coeffs = np.array(init_dict['COST']['coeff'])\n",
    "\n",
    "    U1_var = init_dict['TREATED']['var']\n",
    "    U0_var = init_dict['UNTREATED']['var']\n",
    "\n",
    "    V_var = init_dict['COST']['var']\n",
    "\n",
    "    U1V_rho = init_dict['RHO']['treated']\n",
    "    U0V_rho = init_dict['RHO']['untreated']\n",
    "\n",
    "    # Auxiliary objects\n",
    "    U1V_cov = U1V_rho * np.sqrt(U1_var) * np.sqrt(V_var)\n",
    "    U0V_cov = U0V_rho * np.sqrt(U0_var) * np.sqrt(V_var)\n",
    "\n",
    "    num_covars_out = Y1_coeffs.shape[0]\n",
    "    num_covars_cost = C_coeffs.shape[0]\n",
    "\n",
    "    # Simulate observables\n",
    "    means = np.tile(0.0, num_covars_out)\n",
    "    covs = np.identity(num_covars_out)\n",
    "\n",
    "    X = np.random.multivariate_normal(means, covs, num_agents)\n",
    "    X[:, 0] = 1.0\n",
    "\n",
    "    means = np.tile(0.0, num_covars_cost)\n",
    "    covs = np.identity(num_covars_cost)\n",
    "\n",
    "    Z = np.random.multivariate_normal(means, covs, num_agents)\n",
    "\n",
    "    # Construct index of observable characteristics\n",
    "    Y1_level = np.dot(Y1_coeffs, X.T)\n",
    "    Y0_level = np.dot(Y0_coeffs, X.T)\n",
    "    C_level = np.dot(C_coeffs, Z.T)\n",
    "\n",
    "    # Simulate unobservables\n",
    "    means = np.tile(0.0, 3)\n",
    "    vars_ = [U1_var, U0_var, V_var]\n",
    "    covs = np.diag(vars_)\n",
    "\n",
    "    covs[0, 2] = U1V_cov\n",
    "    covs[2, 0] = covs[0, 2]\n",
    "\n",
    "    covs[1, 2] = U0V_cov\n",
    "    covs[2, 1] = covs[1, 2]\n",
    "\n",
    "    U = np.random.multivariate_normal(means, covs, num_agents)\n",
    "\n",
    "    # Simulate endogenous variables\n",
    "    Y1 = np.tile(np.nan, num_agents)\n",
    "    Y0 = np.tile(np.nan, num_agents)\n",
    "    Y = np.tile(np.nan, num_agents)\n",
    "\n",
    "    D = np.tile(np.nan, num_agents)\n",
    "\n",
    "    for i in range(num_agents):\n",
    "\n",
    "        # Select individual unobservables and observables\n",
    "        u1, u0, v = U[i, 0], U[i, 1], U[i, 2]\n",
    "\n",
    "        y1_idx, y0_idx, c_idx = Y1_level[i], Y0_level[i], C_level[i]\n",
    "\n",
    "        # Decision Rule\n",
    "        expected_benefits = y1_idx - y0_idx\n",
    "        cost = c_idx + v\n",
    "\n",
    "        d = np.float((expected_benefits - cost > 0))\n",
    "\n",
    "        # Potential outcomes\n",
    "        y1, y0 = y1_idx + u1, y0_idx + u0\n",
    "\n",
    "        # Observed outcomes\n",
    "        y = d * y1 + (1.0 - d) * y0\n",
    "\n",
    "        # Collect data matrices\n",
    "        Y[i], Y0[i], Y1[i], D[i] = y, y1, y0, d\n",
    "\n",
    "    # Check integrity of simulated data\n",
    "    _check_integrity_simulate(Y1, Y0, Y, D)\n",
    "\n",
    "    # Save to disk\n",
    "    _write_out(Y, D, X, Z, file_name, unobserved, Y1, Y0)\n",
    "\n",
    "    # Return selected features of data\n",
    "    return Y1, Y0, D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check if it is all working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_dict = process('init.ini')\n",
    "\n",
    "Y1, Y0, D = simulate(init_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our parametrization, let us revisit our objects of interest. We start with the individual-specific benefits. Please note the use of the [StatsModels](http://statsmodels.sourceforge.net/devel/index.html) library,\n",
    "that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration. Think of it as a replacement for using [R](http://www.r-project.org/). In general, [rpy2](http://rpy.sourceforge.net/rpy2.html) provides a low-level interface to R from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Auxiliary variables\n",
    "B = Y1 - Y0\n",
    "\n",
    "# Create histogram and density estimate of benefits.\n",
    "kde = sm.nonparametric.KDEUnivariate(B)\n",
    "kde.fit()\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(B, bins=50, normed=True, color='blue')\n",
    "ax.plot(kde.support, kde.density, lw=2, color='black')\n",
    "fig.suptitle('Distribution of Individual-Specific Benefits', fontsize=20)\n",
    "ax.set_xlabel('Individual-Specific Benefits', fontsize=18)\n",
    "ax.set_ylabel('Density and Histogram', fontsize=18)\n",
    "yticks = ax.yaxis.get_major_ticks()\n",
    "yticks[0].set_visible(False)\n",
    "\n",
    "# Calcuate the average treatment effects\n",
    "ate, tt, tut = np.mean(B), np.mean(B[D==1]), np.mean(B[D==0])\n",
    "\n",
    "# Pretty formatting of strings and output\n",
    "fmt = '     {0:<5}{1:10.2f}\\n'\n",
    "\n",
    "print '\\nAverage Treatment Effects\\n'\n",
    "print fmt.format('ATE ', ate)\n",
    "print fmt.format('TT', tt)\n",
    "print fmt.format('TUT ', tut)\n",
    "\n",
    "# Let us add them to our plot.\n",
    "plt.axvline(x=ate, ymin=0, ymax=5, linewidth=2, color='g')\n",
    "plt.axvline(x=tt, ymin=0, ymax=5, linewidth=2, color='b')\n",
    "plt.axvline(x=tut, ymin=0, ymax=5, linewidth=2, color='y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "\n",
    "Now, we will perform Maximum Likelihood Estimation using alternative optimization algorithms. Here is the likelihood function:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta; X, Z) =\\sum^N_{i=1} D\\mathcal{L_{i,1}} + (1 - D)\\mathcal{L_{i,0}},\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L_1} = & \\log\\left(\\frac{1}{\\sigma_{U_1}}\\phi\\left(\\frac{Y_i - X_i\\beta_1}{\\sigma_{U_1}}\\right)\\Phi\\left(\\frac{Z_i\\gamma - \\sigma_V/\\sigma_{U_1}(Y_i - X_i\\beta_1)}{\\sqrt{(1 - \\rho_{U_1,V})*\\sigma^2_{V}}}\\right)\\right) \\\\\n",
    "\\mathcal{L_0} =  &\\log\\left(\\frac{1}{\\sigma_{U_0}}\\phi\\left(\\frac{Y_i - X_i\\beta_0}{\\sigma_{U_0}}\\right)\\Phi\\left(\\frac{Z_i\\gamma - \\sigma_V/\\sigma_{U_0}(Y_i - X_i\\beta_0)}{\\sqrt{(1 - \\rho_{U_0,V})*\\sigma^2_{V}}}\\right)\\right) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _distribute_parameters(x, init_dict, num_covars_out):\n",
    "    \"\"\" Distribute the parameters.\n",
    "    \"\"\"\n",
    "    # Antibugging\n",
    "    assert (isinstance(x, np.ndarray))\n",
    "    assert (isinstance(num_covars_out, int))\n",
    "    assert (num_covars_out > 0)\n",
    "\n",
    "    # Initialize containers\n",
    "    rslt = dict()\n",
    "\n",
    "    rslt['TREATED'] = dict()\n",
    "    rslt['UNTREATED'] = dict()\n",
    "    rslt['COST'] = dict()\n",
    "    rslt['RHO'] = dict()\n",
    "\n",
    "    # Distribute parameters\n",
    "    rslt['TREATED']['all'] = x[:num_covars_out]\n",
    "    rslt['UNTREATED']['all'] = x[num_covars_out:(2 * num_covars_out)]\n",
    "\n",
    "    rslt['COST']['all'] = x[(2 * num_covars_out):(-4)]\n",
    "    rslt['COST']['var'] = init_dict['COST']['var']\n",
    "\n",
    "\n",
    "    rslt['TREATED']['var'] = np.exp(x[(-4)])\n",
    "    rslt['UNTREATED']['var'] = np.exp(x[(-3)])\n",
    "\n",
    "    rslt['RHO']['treated'] = -1.0 + 2.0 / (1.0 + float(np.exp(-x[-2])))\n",
    "    rslt['RHO']['untreated'] = -1.0 + 2.0 / (1.0 + float(np.exp(-x[-1])))\n",
    "\n",
    "    # Update auxiliary versions\n",
    "    rslt['AUX'] = dict()\n",
    "\n",
    "    rslt['AUX']['x_internal'] = x.copy()\n",
    "    rslt['AUX']['x_internal'][-4] = np.exp(x[(-4)])\n",
    "    rslt['AUX']['x_internal'][-3] = np.exp(x[(-3)])\n",
    "    rslt['AUX']['x_internal'][-2] = -1.0 + 2.0 / (1.0 + float(np.exp(-x[-2])))\n",
    "    rslt['AUX']['x_internal'][-1] = -1.0 + 2.0 / (1.0 + float(np.exp(-x[-1])))\n",
    "\n",
    "    # Finishing.\n",
    "    return rslt\n",
    "\n",
    "\n",
    "def _max_interface(x, Y, D, X, Z,init_dict):\n",
    "    \"\"\" Interface to the SciPy maximization routines.\n",
    "    \"\"\"\n",
    "    # Auxiliary objects\n",
    "    num_covars_out = X.shape[1]\n",
    "    \n",
    "    # Collect maximization arguments\n",
    "    rslt = _distribute_parameters(x, init_dict, num_covars_out)\n",
    "\n",
    "    # Calculate likelihood\n",
    "    likl = _negative_log_likelihood(rslt, Y, D, X, Z)\n",
    "\n",
    "    # Finishing.\n",
    "    return likl\n",
    "\n",
    "\n",
    "def _negative_log_likelihood(args, Y, D, X, Z):\n",
    "    \"\"\" Negative log-likelihood evaluation.\n",
    "    \"\"\"\n",
    "    # Distribute parametrization\n",
    "    Y1_coeffs = np.array(args['TREATED']['all'])\n",
    "    Y0_coeffs = np.array(args['UNTREATED']['all'])\n",
    "    C_coeffs = np.array(args['COST']['all'])\n",
    "\n",
    "    U1_var = args['TREATED']['var']\n",
    "    U0_var = args['UNTREATED']['var']\n",
    "\n",
    "    var_V = args['COST']['var']\n",
    "\n",
    "    U1V_rho = args['RHO']['treated']\n",
    "    U0V_rho = args['RHO']['untreated']\n",
    "\n",
    "    # Auxiliary objects.\n",
    "    U1_sd = np.sqrt(U1_var)\n",
    "    U0_sd = np.sqrt(U0_var)\n",
    "    V_sd = np.sqrt(var_V)\n",
    "\n",
    "    num_agents = Y.shape[0]\n",
    "    choice_coeffs = np.concatenate((Y1_coeffs - Y0_coeffs, - C_coeffs))\n",
    "\n",
    "    # Initialize containers\n",
    "    likl = np.tile(np.nan, num_agents)\n",
    "    choice_idx = np.tile(np.nan, num_agents)\n",
    "\n",
    "    # Likelihood construction.\n",
    "    for i in range(num_agents):\n",
    "\n",
    "        G = np.concatenate((X[i, :], Z[i, :]))\n",
    "        choice_idx[i] = np.dot(choice_coeffs, G)\n",
    "\n",
    "        # Select outcome information\n",
    "        if D[i] == 1.00:\n",
    "\n",
    "            coeffs, rho, sd = Y1_coeffs, U1V_rho, U1_sd\n",
    "        else:\n",
    "            coeffs, rho, sd = Y0_coeffs, U0V_rho, U0_sd\n",
    "\n",
    "        arg_one = (Y[i] - np.dot(coeffs, X[i, :])) / sd\n",
    "        arg_two = (choice_idx[i] - rho * V_sd * arg_one) / \\\n",
    "                  np.sqrt((1.0 - rho ** 2) * var_V)\n",
    "\n",
    "        pdf_evals, cdf_evals = norm.pdf(arg_one), norm.cdf(arg_two)\n",
    "\n",
    "        if D[i] == 1.0:\n",
    "            contrib = (1.0 / float(sd)) * pdf_evals * cdf_evals\n",
    "        else:\n",
    "            contrib = (1.0 / float(sd)) * pdf_evals * (1.0 - cdf_evals)\n",
    "\n",
    "        likl[i] = contrib\n",
    "\n",
    "    # Transformations.\n",
    "    likl = -np.mean(np.log(np.clip(likl, 1e-20, np.inf)))\n",
    "\n",
    "    # Quality checks.\n",
    "    assert (isinstance(likl, float))\n",
    "    assert (np.isfinite(likl))\n",
    "\n",
    "    # Finishing.\n",
    "    return likl\n",
    "\n",
    "\n",
    "def _load_data(init_dict):\n",
    "    \"\"\" Load dataset.\n",
    "    \"\"\"\n",
    "    # Auxiliary objects\n",
    "    num_covars_out = init_dict['AUX']['num_covars_out']\n",
    "    num_covars_cost = init_dict['AUX']['num_covars_cost']\n",
    "    num_agents = init_dict['BASICS']['agents']\n",
    "\n",
    "    # Read dataset\n",
    "    data = np.genfromtxt(init_dict['BASICS']['file'])\n",
    "\n",
    "    # Reshaping, this ensure that the program also runs with just one agent\n",
    "    # as otherwise only an vector is created. This creates problems for the\n",
    "    # subsetting of the overall data into the components.\n",
    "    data = np.array(data, ndmin=2)\n",
    "\n",
    "    # Distribute data\n",
    "    Y, D = data[:, 0], data[:, 1]\n",
    "\n",
    "    X, Z = data[:, 2:(num_covars_out + 2)], data[:, -num_covars_cost:]\n",
    "\n",
    "    # Finishing\n",
    "    return Y, D, X, Z\n",
    "\n",
    "\n",
    "def _get_start(which, init_dict):\n",
    "    \"\"\" Get different kind of starting values.\n",
    "    \"\"\"\n",
    "    # Antibugging.\n",
    "    assert (which in ['random', 'init'])\n",
    "\n",
    "    # Distribute auxiliary objects\n",
    "    num_paras = init_dict['AUX']['num_paras']\n",
    "\n",
    "    # Select relevant values.\n",
    "    if which == 'random':\n",
    "        x0 = np.random.uniform(size=num_paras)\n",
    "\n",
    "        # Variances\n",
    "        x0[(-4)] = max(x0[(-4)], 0.01)\n",
    "        x0[(-3)] = max(x0[(-3)], 0.01)\n",
    "\n",
    "        # Correlations\n",
    "        x0[(-2)] -= 0.5\n",
    "        x0[(-1)] -= 0.5\n",
    "\n",
    "    elif which == 'init':\n",
    "        x0 = np.array(init_dict['AUX']['init_values'][:])\n",
    "    else:\n",
    "        raise AssertionError\n",
    "\n",
    "    # Document starting values\n",
    "    init_dict['AUX']['start_values'] = x0.copy()\n",
    "\n",
    "    # Transform to real line\n",
    "    x0 = _transform_start(x0)\n",
    "\n",
    "    # Type conversion\n",
    "    x0 = np.array(x0)\n",
    "\n",
    "    # Quality assurance.\n",
    "    assert (np.all(np.isfinite(x0)))\n",
    "\n",
    "    # Finishing.\n",
    "    return x0\n",
    "\n",
    "\n",
    "def _transform_start(x):\n",
    "    \"\"\" Transform starting values to cover the whole real line.\n",
    "    \"\"\"\n",
    "\n",
    "    # Coefficients\n",
    "    x[:(-4)] = x[:(-4)]\n",
    "\n",
    "    # Variances\n",
    "    x[(-4)] = np.log(x[(-4)])\n",
    "    x[(-3)] = np.log(x[(-3)])\n",
    "\n",
    "    # Correlations\n",
    "    transform = (x[(-2)] + 1) / 2\n",
    "    x[(-2)] = np.log(transform / (1.0 - transform))\n",
    "\n",
    "    transform = (x[(-1)] + 1) / 2\n",
    "    x[(-1)] = np.log(transform / (1.0 - transform))\n",
    "\n",
    "    # Finishing\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us evaluate the criterion function and see if that part is working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a function for the estimation. It builds on all our previously defined elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load model information\n",
    "init_dict  = process('init.ini') \n",
    "\n",
    "Y, D, X, Z = _load_data(init_dict)\n",
    "\n",
    "likl = _negative_log_likelihood(init_dict, Y, D, X, Z)\n",
    "\n",
    "print 'Evaluation of criterion function', likl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def estimate(init_dict):\n",
    "    \"\"\" Estimate our version of the generalized Roy model.\n",
    "    \"\"\"\n",
    "    # Antibugging\n",
    "    assert (isinstance(init_dict, dict))\n",
    "\n",
    "    # Load dataset\n",
    "    Y, D, X, Z = _load_data(init_dict)\n",
    "\n",
    "    # Create auxiliary objects\n",
    "    start = init_dict['ESTIMATION']['start']\n",
    "    maxiter = init_dict['ESTIMATION']['maxiter']\n",
    "\n",
    "    optimizer = init_dict['ESTIMATION']['optimizer']\n",
    "    num_covars_out = init_dict['AUX']['num_covars_out']\n",
    "\n",
    "    # Initialize different starting values\n",
    "    x0 = _get_start(start, init_dict)\n",
    "\n",
    "    # Select optimizer\n",
    "    raise NotImplementedError, 'Code Missing'\n",
    "\n",
    "    # Provide additional arguments to the optimizer\n",
    "    opts = dict()\n",
    "\n",
    "    opts['maxiter'] = maxiter\n",
    "\n",
    "    # Run optimization or just evaluate function at starting values\n",
    "    if maxiter == 0:\n",
    "\n",
    "        # Collect maximization arguments.\n",
    "        raise NotImplementedError, 'Code Missing'\n",
    "\n",
    "        # Calculate likelihood according to user's request\n",
    "        raise NotImplementedError, 'Code Missing'\n",
    "\n",
    "        # Compile results\n",
    "        x_rslt, fun, success = x0, likl, False\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Check out the SciPy documentation for details about the interface\n",
    "        # to the `minimize' function that provides a convenient interface to\n",
    "        #  a variety of alternative maximization algorithms. You will also\n",
    "        # find information about the return information.\n",
    "        raise NotImplementedError, 'Code Missing'\n",
    "\n",
    "        # Compile results\n",
    "        x_rslt, fun = opt_rslt['x'], opt_rslt['fun']\n",
    "        success = opt_rslt['success']\n",
    "\n",
    "    # Tranformation to internal parameters\n",
    "    rslt = _distribute_parameters(x_rslt, init_dict, num_covars_out)\n",
    "\n",
    "    rslt['fval'], rslt['success'] = fun, success\n",
    "\n",
    "    # Finishing\n",
    "    return rslt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us actually run some estimations. Our current implementation allow to easily switch between alternative optimzation algorithms and starting values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Process model specification\n",
    "init_dict = process('init.ini')\n",
    "\n",
    "# Simulate a synthetic sample\n",
    "simulate(init_dict)\n",
    "\n",
    "# Estimate the generalized Roy model\n",
    "for optimizer in ['bfgs', 'nm']:\n",
    "    \n",
    "    init_dict['ESTIMATION']['optimizer'] = optimizer\n",
    "    \n",
    "    for start in ['random', 'init']:\n",
    "        \n",
    "        init_dict['ESTIMATION']['start'] = start\n",
    "\n",
    "        # Monitoring\n",
    "        print '\\n\\n Current Request \\n'\n",
    "        \n",
    "        print ' Optimizer: ', optimizer\n",
    "        \n",
    "        print ' Start:     ', start\n",
    "        \n",
    "        # Run estimation\n",
    "        rslt = estimate(init_dict)\n",
    "        \n",
    "        # Inspect subset of results\n",
    "        print ' Variances: ', rslt['TREATED']['var'], rslt['UNTREATED']['var']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection of Results\n",
    "\n",
    "After conduction an estimation, the focus shifts back to the economic interpretation of our results. As we often have to study the results from hundreds of different estimation runs, it is convenient to have a function set up that produces the main objects of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inspect(rslt, init_dict):\n",
    "    \"\"\" This function simulates a sample from the estimates of the model\n",
    "        and reports the average effects of treatment in a file.\n",
    "    \"\"\"\n",
    "    # Antibugging\n",
    "    assert (isinstance(rslt, dict))\n",
    "    assert (isinstance(init_dict, dict))\n",
    "\n",
    "    # Update results\n",
    "    raise NotImplementedError, 'Code Missing'\n",
    "\n",
    "    # Modified dataset\n",
    "    modified_init['BASICS']['file'] = 'simulated.txt'\n",
    "\n",
    "    # Simulate from estimation results\n",
    "    Y1, Y0, D = simulate(modified_init, True)\n",
    "\n",
    "    # Calculate the average treatment effects\n",
    "    B = Y1 - Y0\n",
    "\n",
    "    effects = []\n",
    "    effects += [np.mean(B)]\n",
    "    effects += [np.mean(B[D == 1])]\n",
    "    effects += [np.mean(B[D == 0])]\n",
    "\n",
    "    # Print selected results to file\n",
    "    with open('results.txt', 'w') as file_:\n",
    "\n",
    "        file_.write('\\n softEcon: Generalized Roy Model')\n",
    "        file_.write('\\n -------------------------------\\n')\n",
    "\n",
    "        # Average effects of treatment\n",
    "        fmt = '     {0:<5}{1:10.2f}\\n\\n'\n",
    "\n",
    "        file_.write('\\n Average Treatment Effects\\n\\n')\n",
    "\n",
    "        for i, label in enumerate(['ATE', 'TT', 'TUT']):\n",
    "\n",
    "             raise NotImplementedError, 'Code Missing'\n",
    "\n",
    "        file_.write('\\n Parameters\\n\\n')\n",
    "        file_.write('     Start    Finish\\n\\n')\n",
    "\n",
    "        num_paras = init_dict['AUX']['num_paras']\n",
    "\n",
    "        # Structural parameters\n",
    "        x0, x = init_dict['AUX']['start_values'], rslt['AUX']['x_internal']\n",
    "\n",
    "        fmt = '{0:10.2f}{1:10.2f}\\n'\n",
    "\n",
    "        for i in range(num_paras):\n",
    "\n",
    "            str_ = fmt.format(x0[i], x[i])\n",
    "\n",
    "            file_.write(str_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Process initialization file\n",
    "init_dict = process('init.ini')\n",
    "\n",
    "# Simulate synthetic sample\n",
    "simulate(init_dict)\n",
    "\n",
    "# Estimate model\n",
    "rslt = estimate(init_dict)\n",
    "\n",
    "# Write results\n",
    "inspect(rslt, init_dict)\n",
    "\n",
    "# Inspect the results\n",
    "%cat results.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of all files that have the file extension `.txt'.\n",
    "files = glob.glob('*.txt')\n",
    "\n",
    "# Remove files\n",
    "for file_ in files:\n",
    "    \n",
    "    os.remove(file_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Aakvik, A., Heckman, J. J., and Vytlacil, E. J. (2005). Treatment Effects for Discrete Outcomes When Responses to Treatment Vary Among Observationally Identical Persons: An Application to Norwegian Vocational Rehabilitation Programs. *Journal of Econometrics*, 125(1-2):15–51.\n",
    "\n",
    "Abbring, J. and Heckman, J. J. (2007). Econometric Evaluation of Social Programs, Part III: Distributional Treatment Effects, Dynamic Treatment Effects, Dynamic Discrete Choice, and General Equilibrium Policy Evaluation. In Heckman, J. J. and Leamer, E. E., editors, *Handbook of Econometrics*, volume 6B, pages 5145–5303. Elsevier Science, Amsterdam, Netherlands\n",
    "\n",
    "Browning, M., Heckman, J. J., and Hansen, L. P. (1999). Micro Data and General Equilibrium Models. In Taylor, J. B. and Woodford, M., editors, *Handbook of Macroeconomics*, volume 1A, pages 543–633. Elsevier Science, Amsterdam, Netherlands.\n",
    "\n",
    "Carneiro, P., Hansen, K., and Heckman, J. J. (2003). Estimating Distributions of Treatment Effects with an Application to the Returns to Schooling and Measurement of the Effects of Uncertainty on College Choice. *International Economic Review*, 44(2):361–422.\n",
    "\n",
    "Eisenhauer, P. (2012). Issues in the Economics and Econometrics\n",
    "of Policy Evaluation: Explorations Using a Factor Structure Model. Unpublished Manuscript.\n",
    "\n",
    "Heckman, J. J. (2001). Micro Data, Heterogeneity, and the Evaluation of Public Policy: Nobel Lecture. *Journal of Political Economy*, 109(4):673–748.\n",
    "\n",
    "Heckman, J. J., Smith, J., and Clements, N. (1997). Making the Most Out of Programme Evaluations and Social Experiments: Accounting for Heterogeneity in Programme Impacts. *The Review of Economic Studies*, 64(4):487–535.\n",
    "\n",
    "Heckman, J. J. and Vytlacil, E. J. (2007a). Econometric Evaluation of Social Programs, Part I: Causal Effects, Structural Models and Econometric Policy Evaluation. In Heckman, J. J. and Leamer, E. E., editors, *Handbook of Econometrics*, volume 6B, pages 4779–4874. Elsevier Science, Amsterdam, Netherlands.\n",
    "\n",
    "Heckman, J. J. and Vytlacil, E. J. (2007b). Econometric Evaluation of Social Programs, Part II: Using the Marginal Treatment Effect to Organize Alternative Economic Estimators to Evaluate Social Programs and to Forecast their Effects in New Environments. In Heckman, J. J. and Leamer, E. E., editors, *Handbook of Econometrics*, volume 6B, pages 4875–5144. Elsevier Science, Amsterdam, Netherlands.\n",
    "\n",
    "Quandt, R. E. (1958). The Estimation of the Parameters of a Linear Regression System Obeying two Separate Regimes. *Journal of the American Statistical Association*, 53(284):873–880.\n",
    "\n",
    "Quandt, R. E. (1958). The Estimation of the Parameters of a Linear Regression System Obeying two Separate Regimes. *Journal of the American Statistical Association*, 53(284):873–880."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
